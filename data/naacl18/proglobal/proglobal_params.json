{
  "dataset_reader": {
    "type": "ProGlobalDatasetReader",
    "token_indexers": {
      "tokens_list": {
        "type": "single_id",
        "namespace": "tokens_list",
        "lowercase_tokens": true
      }
    },
    "token_position_indexers": {
      "token_positions_list": {
        "type": "single_id",
        "namespace": "token_positions_list",
        "lowercase_tokens": true
      }
    },
    "sent_position_indexers": {
      "sent_positions_list": {
        "type": "single_id",
        "namespace": "sent_positions_list",
        "lowercase_tokens": true
      }
    }
  },
  "train_data_path": "data/naacl18/proglobal/all.chain.train.v3",
  "validation_data_path": "data/naacl18/proglobal/all.chain.dev.v3",
  "test_data_path": "data/naacl18/proglobal/all.chain.test.v3",
  "evaluate_on_test": true,
  "model": {
    "type": "ProGlobal",
    "text_field_embedder": {
      "tokens_list": {
        "type": "embedding",
        "vocab_namespace": "tokens_list",
	"pretrained_file": "data/glove.6B.100d.txt.gz",
        // Download glove embeddings file from https://nlp.stanford.edu/projects/glove/        
        "embedding_dim": 100,
        "trainable": true
      }
    },
    "pos_field_embedder": {
      "token_positions_list": {
        "type": "embedding",
        "vocab_namespace": "token_positions_list",
        "embedding_dim": 50,
        "trainable": true
      }
    },
    "sent_pos_field_embedder": {
      "sent_positions_list": {
        "type": "embedding",
        "vocab_namespace": "sent_positions_list",
        "embedding_dim": 50,
        "trainable": true
      }
    },
    "modeling_layer": {
      "type": "lstm",
      "input_size": 200,
      "hidden_size": 100,
      "num_layers": 1,
      "bidirectional": true
    },
    "span_end_encoder_bef": {
      "type": "lstm",
      "input_size": 400,
      "hidden_size": 10,
      "num_layers": 1
    },
    "span_start_encoder_aft": {
      "type": "lstm",
      "input_size": 400,
      "hidden_size": 10,
      "num_layers": 1
    },
    "span_end_encoder_aft": {
      "type": "lstm",
      "input_size": 400,
      "hidden_size": 10,
      "num_layers": 1
    }
  },
  "iterator": {
    "type": "bucket",
    "padding_noise": 0.0,
    "sorting_keys": [["tokens_list", "num_fields"]],
    "batch_size": 30
  },
  "trainer": {
    "num_epochs": 100,
    "grad_norm": 10.0,
    "patience" : 30,
    "cuda_device" : -1,
    "optimizer": {
      "type": "adadelta",
      "lr": 0.5,
      "rho": 0.95
    }
  }
}
