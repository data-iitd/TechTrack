{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, requests, json, collections, os\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z0-9-_]')\n",
    "import xlwt \n",
    "from xlwt import Workbook\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_properties = {}\n",
    "category_properties['Hardware-Devices'] = ['notRelevant','isPowered','isConnected','isSetup','isUsed']\n",
    "category_properties['Software-Device-Drivers'] = ['notRelevant','isInstalled','isRelatedDeviceConnected','isSettingsChanged']\n",
    "category_properties['Software-OS-Related'] = ['notRelevant','isOpened','isSettingsChanged']\n",
    "category_properties['Software-Other'] = ['notRelevant','isInstalled','isOpened','isSettingsChanged']\n",
    "category_properties['Hardware-Other'] = ['']\n",
    "\n",
    "property_event = {}\n",
    "property_event['notRelevant'] = True\n",
    "property_event['isPowered'] = False\n",
    "property_event['isConnected'] = False\n",
    "property_event['isSetup'] = True\n",
    "property_event['isUsed'] = True\n",
    "property_event['isInstalled'] = False\n",
    "property_event['isRelatedDeviceConnected'] = False\n",
    "property_event['isSettingsChanged'] = True\n",
    "property_event['isOpened'] = False\n",
    "\n",
    "property_values = {}\n",
    "property_values[True] = ['true','false']\n",
    "property_values[False] = ['f->t','t->f','noChange','start-T','start-F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_details = []\n",
    "mentions = {}\n",
    "entities = {}\n",
    "filter_prop = 'isOpened'\n",
    "f = open('./annotations/state_change_annotations_'+filter_prop+'.tsv','w',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(word):\n",
    "    w = word\n",
    "    cap = False\n",
    "    if(w.isupper()):\n",
    "        cap = True\n",
    "    w = w.lower()\n",
    "#     print(w)\n",
    "    if('\\'s' == w):\n",
    "        w=''\n",
    "    if('cd' == w):\n",
    "        w='CD'\n",
    "    w = lemmatizer.lemmatize(w)\n",
    "#     print(w)\n",
    "    if(not cap):\n",
    "        w = w.capitalize()\n",
    "    else:\n",
    "        w = w.upper()\n",
    "    w = regex.sub('', w)\n",
    "    if(len(w)<2 and w!= 'X'):\n",
    "        w=''\n",
    "    return w\n",
    "\n",
    "def get_line(offset):\n",
    "    for i, step in enumerate(step_details):\n",
    "        if(int(offset)<step[2]):\n",
    "            return i-2\n",
    "    return len(step_details)-1\n",
    "def clean_text(ent_text):\n",
    "    ent_words = ent_text.split(' ')\n",
    "    ent_words = [process_word(word) for word in ent_words]\n",
    "    ent_text = ' '.join(ent_words).strip()\n",
    "    return ent_text\n",
    "def get_text(mention):\n",
    "    text = mentions[mention][-2]\n",
    "    while(entities[text][0] != '' and entities[text][0] != text):\n",
    "        text = entities[text][0]\n",
    "    return text\n",
    "def get_base_ent(text):\n",
    "    while(entities[text][0] != '' and entities[text][0] != text):\n",
    "        text = entities[text][0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotations(doc_id=1,folder='config/',file='monitor',filter_prop=''):\n",
    "    global entities, mentions, step_details\n",
    "    config_file = folder+file+'.ann'\n",
    "    text_file = folder+file+'.txt'\n",
    "    annotations = open(config_file,'r',encoding='utf-8').readlines()\n",
    "    raw_text = open(text_file,'r',encoding='utf-8').read().strip()\n",
    "    steps = raw_text.split('\\n\\n')\n",
    "    \n",
    "    step_details = []\n",
    "    start = 0\n",
    "    start2 = 0\n",
    "    for i, step in enumerate(steps):\n",
    "        length = len(step)\n",
    "        newlines = step.count('\\n')\n",
    "        step_details.append([i,step,start,start2,length,newlines])\n",
    "        start+=length+newlines+4 ### accounting for '\\n' diff in Brat\n",
    "        start2+=2+length\n",
    "    #     if(i==3):\n",
    "    #         print(step,'\\n\\n',newlines)\n",
    "    num_steps = len(step_details) - 1\n",
    "    \n",
    "    entities = {} #base-entity, mentions\n",
    "    mentions = {} #ent_id, line_no, ent_cat, start, end, ent_text, properties\n",
    "    for line in annotations:\n",
    "        line=line.strip()\n",
    "        if(line[0]=='T'): ### entities\n",
    "            ent_id, ent_cat, ent_text = line.split('\\t')\n",
    "            ent_text = clean_text(ent_text)\n",
    "            ent_cat, start, end = ent_cat.split(' ')\n",
    "            line_no = get_line(start)\n",
    "            start,end,line_no = int(start),int(end),int(line_no)\n",
    "            mentions[ent_id] = [ent_id, line_no,ent_cat,start,end,ent_text,{}]\n",
    "            if(ent_text not in entities):\n",
    "                entities[ent_text]=['',[]]\n",
    "            entities[ent_text][1].append(ent_id)\n",
    "    #         print(ent_id,ent_cat,start,end,line_no,ent_text,sep='\\n')\n",
    "    #         break\n",
    "        elif(line[0]=='A'): ### attributes\n",
    "            atr_id, atr_type = line.split('\\t')\n",
    "            split = atr_type.split(' ')\n",
    "            if(len(split)==2):\n",
    "                split.append('true')\n",
    "            atr_type, atr_ent, atr_val = split\n",
    "            mentions[atr_ent][-1][atr_type]=atr_val\n",
    "    #         print(atr_id,atr_type, atr_ent, atr_val,sep='\\n')\n",
    "    #         break\n",
    "        elif(line[0]=='*'): ### equiv\n",
    "            _, rel_type = line.split('\\t')\n",
    "            rels = rel_type.split(' ')\n",
    "            rel_type, ent1, ent2 = rels[0], rels[1], rels[2]\n",
    "            text1, text2 = get_text(ent1), get_text(ent2)\n",
    "            if(text1==text2):\n",
    "                continue\n",
    "            base, other = text2, text1\n",
    "            if(len(text1)<=len(text2)):\n",
    "                base, other = text1, text2\n",
    "            entities[other][0]=base\n",
    "    #         print(entities[other][0],base,sep=',')\n",
    "        elif(line[0]=='R'): ### relation- subpart\n",
    "            rel_id, rel_type = line.split('\\t')\n",
    "            rel_type, sub, main = rel_type.split(' ')\n",
    "            sub, main = sub.split(':')[1],main.split(':')[1]\n",
    "            sub, main = get_text(sub), get_text(main)\n",
    "            entities[sub][0] = main\n",
    "    #         print(rel_id,rel_type,sub,main,sep=',\\t')\n",
    "        else:\n",
    "            print(line)\n",
    "    \n",
    "    merged_ents = {} ### merge entities with base-subpart-equiv\n",
    "    for ent in entities:\n",
    "        base_ent = get_base_ent(ent)\n",
    "        if(base_ent not in merged_ents):\n",
    "            merged_ents[base_ent] = {}\n",
    "        for mention_id in entities[ent][1]:\n",
    "            mention = mentions[mention_id]\n",
    "            line_no = mention[1]\n",
    "            if(line_no not in merged_ents[base_ent]):\n",
    "                merged_ents[base_ent][line_no] = mention\n",
    "            else:\n",
    "                merged_ents[base_ent][line_no][-1].update(mention[-1])\n",
    "\n",
    "    clean_ents = []\n",
    "    for ent in merged_ents:\n",
    "        if(all(merged_ents[ent][line_no][-1]=={} for line_no in merged_ents[ent])):\n",
    "            clean_ents.append(ent)\n",
    "    for ent in clean_ents:\n",
    "        del merged_ents[ent]\n",
    "        \n",
    "    step_wise_properties = {}\n",
    "\n",
    "    for ent in merged_ents:\n",
    "        mention = mentions[entities[ent][1][0]]\n",
    "        category = mention[2]\n",
    "        if(category == 'Hardware-Other'):\n",
    "            continue\n",
    "        properties = category_properties[category]\n",
    "        ent_properties = {}\n",
    "        for prop in properties:\n",
    "            prop_val = ['']*(num_steps+1)\n",
    "            prop_val[0]='False'\n",
    "    #         print(sorted(merged_ents[ent]))\n",
    "    #         break\n",
    "    #         ent_mentions = [mentio]\n",
    "    #         ent_mentions = sorted(merged_ents[ent])\n",
    "            if(property_event[prop]):\n",
    "                for step_no in range(0,num_steps):\n",
    "                    if(step_no in merged_ents[ent] and prop in merged_ents[ent][step_no][-1]):\n",
    "                        val = merged_ents[ent][step_no][-1][prop].capitalize()\n",
    "                        prop_val[step_no+1] = val\n",
    "                    else:\n",
    "                        prop_val[step_no+1] = 'False'\n",
    "            else:\n",
    "                for step_no in range(0,num_steps):\n",
    "                    if(step_no in merged_ents[ent] and prop in merged_ents[ent][step_no][-1]):\n",
    "                        val = merged_ents[ent][step_no][-1][prop]\n",
    "                        if(val=='f->t' and prop_val[step_no]=='False'):\n",
    "                            prop_val[step_no+1] = 'True'\n",
    "                        elif(val=='t->f' and prop_val[step_no]=='True'):\n",
    "                            prop_val[step_no+1] = 'False'\n",
    "                        elif(val=='t->f' and all(val=='False' for val in prop_val[:step_no])):\n",
    "                            for i in range(step_no+1):\n",
    "                                prop_val[i] = 'True'\n",
    "                            prop_val[step_no+1] = 'False'\n",
    "                        elif(val=='start-T'):\n",
    "                            for i in range(step_no+2):\n",
    "                                prop_val[step_no+1] = 'True'\n",
    "                        elif(val=='start-F'):\n",
    "                            for i in range(step_no+2):\n",
    "                                prop_val[step_no+1] = 'False'\n",
    "                        else:\n",
    "                            prop_val[step_no+1] = prop_val[step_no]\n",
    "                    else:\n",
    "                        prop_val[step_no+1] = prop_val[step_no]\n",
    "            if not((filter_prop != '' and prop!=filter_prop) or all(val=='False' for val in prop_val)):\n",
    "                ent_properties[prop]=prop_val\n",
    "    #     print(ent,category,ent_properties,sep='\\n')\n",
    "    #     break\n",
    "        step_wise_properties[ent]=ent_properties\n",
    "    # print(step_wise_properties)\n",
    "\n",
    "    df = pd.DataFrame({'Steps':steps})\n",
    "    for ent in step_wise_properties:\n",
    "        for prop in step_wise_properties[ent]:\n",
    "            if(filter_prop==''):\n",
    "                df[ent+'___'+prop] = step_wise_properties[ent][prop]\n",
    "            else:\n",
    "                df[ent] = step_wise_properties[ent][prop]\n",
    "    df.to_excel('./config/'+file+'.xlsx')\n",
    "    \n",
    "#     headers = list(df.columns)[1:]\n",
    "#     if(len(headers)==0):\n",
    "#         print('\\nSKIPPING',doc_id,folder,file,filter_prop,sep=',\\t')\n",
    "#         return\n",
    "#     print(doc_id,'SID','PARTICIPANTS','\\t'.join(headers),sep='\\t',file=f)\n",
    "#     print(doc_id,'','PROMPT: '+steps[0].split('\\n')[0],'\\t'.join(['-=====' for head in headers]),sep='\\t',file=f)\n",
    "#     print(doc_id,'state1','','\\t'.join(list(df.iloc[0].values)[1:]),sep='\\t',file=f)\n",
    "#     for step_no in range(num_steps):\n",
    "#         states = list(df.iloc[step_no+1].values)\n",
    "#         print(doc_id,'event'+str(step_no+1),repr(states[0])[1:-1],sep='\\t',file=f)\n",
    "#         print(doc_id,'state'+str(step_no+2),'','\\t'.join(states[1:]),sep='\\t',file=f)\n",
    "#     print('\\n',file=f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_annotations(folder='./config/',file='how_to_setup_printer')\n",
    "# parse_annotations(folder='./annotations/OS/',file='224_1___Format_a_PC___Formatting_Your_Primary_Drive')\n",
    "# parse_annotations(folder='./annotations/Headphones/',file='163_1___Connect_a_Headset_to_PC___Connecting_via_Bluetooth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_annotations()\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = './annotations/'\n",
    "# count = 1\n",
    "# for folder in [fol for fol in listdir(data_folder) if not isfile(join(data_folder, fol))]:\n",
    "#     folder = data_folder + folder+'/'\n",
    "#     onlyfiles = [f[:-4] for f in listdir(folder) if f.endswith('.txt')]\n",
    "#     for file in onlyfiles:\n",
    "#         print(count, folder, file)\n",
    "#         parse_annotations(doc_id=count, folder=folder, file=file, filter_prop=filter_prop)\n",
    "#         count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:entities] *",
   "language": "python",
   "name": "conda-env-entities-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
